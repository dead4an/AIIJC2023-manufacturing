{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тюнинг\n",
    "import optuna as opt\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Пайплайн\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "# Данные\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from category_encoders import BinaryEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пути\n",
    "ROOT = os.getcwd()\n",
    "TRAIN_DATASET = os.path.join(ROOT, '../data/train_AIC.csv')\n",
    "TEST_DATASET = os.path.join(ROOT, '../data/test_AIC.csv')\n",
    "\n",
    "# Загрузка\n",
    "train_df = pd.read_csv(TRAIN_DATASET)\n",
    "test_df = pd.read_csv(TEST_DATASET)\n",
    "\n",
    "X, y = train_df.iloc[:, :-1], train_df.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "X_train = X_train.drop([\n",
    "    'Категорийный менеджер', 'Изменение позиции заказа на закупку: изменение даты поставки на бумаге',\n",
    "    'Количество', 'Дней между 0_1', 'Дней между 1_2', 'Дней между 2_3', 'Дней между 3_4', 'Дней между 4_5', \n",
    "    'Дней между 5_6', 'Дней между 6_7', 'Дней между 7_8', 'Согласование заказа 1', 'Согласование заказа 2',\n",
    "    'Согласование заказа 3', 'Изменение даты поставки 7', 'Изменение даты поставки 15', 'Изменение даты поставки 30'\n",
    "    ], axis=1)\n",
    "X_test = X_test.drop([\n",
    "    'Категорийный менеджер', 'Изменение позиции заказа на закупку: изменение даты поставки на бумаге',\n",
    "    'Количество', 'Дней между 0_1', 'Дней между 1_2', 'Дней между 2_3', 'Дней между 3_4', 'Дней между 4_5', \n",
    "    'Дней между 5_6', 'Дней между 6_7', 'Дней между 7_8', 'Согласование заказа 1', 'Согласование заказа 2',\n",
    "    'Согласование заказа 3', 'Изменение даты поставки 7', 'Изменение даты поставки 15', 'Изменение даты поставки 30'\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "сat_features = [\n",
    "    'Поставщик', 'Материал', 'Категорийный менеджер', 'Операционный менеджер',\n",
    "    'Завод', 'Закупочная организация', 'Группа закупок', 'Балансовая единица',\n",
    "    'ЕИ', 'Вариант поставки'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Препроцессоры\n",
    "class DataPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Предобработчик данных \"\"\"\n",
    "    def __init__(self, transform_train=True):\n",
    "        global cat_features\n",
    "        self.transform_train = transform_train\n",
    "        self.bin_encoder = BinaryEncoder(cols=cat_features)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.bin_encoder.fit(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Создаём копию датасета\n",
    "        X_ = X.copy()\n",
    "\n",
    "        # Категориальные фичи\n",
    "        X_ = self.bin_encoder.transform(X_)\n",
    "\n",
    "        # Временные фичи\n",
    "        X_['day_sin'] = np.sin(np.pi * 2 * X_['День недели 2'] / 6)\n",
    "        X_['day_cos'] = np.cos(np.pi * 2 * X_['День недели 2'] / 6)\n",
    "\n",
    "        # Нумерация фич для LGBM (не принимает JSON символы)\n",
    "        X_.columns = [num for num in range(0, len(X_.columns))]\n",
    "\n",
    "        return X_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cat_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_preprocessor \u001b[38;5;241m=\u001b[39m \u001b[43mDataPreprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m X_train_preproc \u001b[38;5;241m=\u001b[39m data_preprocessor\u001b[38;5;241m.\u001b[39mtransform(X_train)\n\u001b[0;32m      3\u001b[0m X_test_preproc \u001b[38;5;241m=\u001b[39m data_preprocessor\u001b[38;5;241m.\u001b[39mtransform(X_test)\n",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m, in \u001b[0;36mDataPreprocessor.__init__\u001b[1;34m(self, transform_train)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m cat_features\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_train \u001b[38;5;241m=\u001b[39m transform_train\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbin_encoder \u001b[38;5;241m=\u001b[39m BinaryEncoder(cols\u001b[38;5;241m=\u001b[39m\u001b[43mcat_features\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cat_features' is not defined"
     ]
    }
   ],
   "source": [
    "data_preprocessor = DataPreprocessor()\n",
    "X_train_preproc = data_preprocessor.transform(X_train)\n",
    "X_test_preproc = data_preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция оптимизации\n",
    "def objective_lgbm(trial: opt.Trial):\n",
    "    # Параметры\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.1, 1, log=True)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 300, 1500, 50)\n",
    "    max_depth = trial.suggest_int('max_depth', 6, 24)\n",
    "    max_bin = trial.suggest_int('max_bin', 64, 256),\n",
    "    num_leaves = trial.suggest_int('num_leaves', 64, 512)\n",
    "    reg_lambda = trial.suggest_float('l2_reg', 0.1, 1.5, log=True)\n",
    "\n",
    "    # Модель\n",
    "    model = LGBMClassifier(\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        reg_lambda=reg_lambda,\n",
    "        max_bin=max_bin,\n",
    "        n_jobs=-1,\n",
    "        force_col_wise=True,\n",
    "        verbose=-1\n",
    "        )\n",
    "\n",
    "    model.fit(X_train_preproc, y_train)\n",
    "    # cv_score = cross_val_score(model, X_train_lgbm, y_train, cv=StratifiedKFold(), scoring='f1_macro', n_jobs=-1)\n",
    "    # accuracy = cv_score.mean()\n",
    "    accuracy = f1_score(y_test, model.predict(X_test_preproc), average='macro')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>187714</th>\n",
       "      <td>231</td>\n",
       "      <td>27439</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6.746477</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41651</th>\n",
       "      <td>33</td>\n",
       "      <td>6056</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5.304034</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102561</th>\n",
       "      <td>629</td>\n",
       "      <td>3566</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6.330550</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31316</th>\n",
       "      <td>31</td>\n",
       "      <td>536</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4.883392</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113039</th>\n",
       "      <td>106</td>\n",
       "      <td>27439</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>9.557131</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119879</th>\n",
       "      <td>308</td>\n",
       "      <td>27439</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>166</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.304557</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103694</th>\n",
       "      <td>2</td>\n",
       "      <td>191</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5.347076</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131932</th>\n",
       "      <td>250</td>\n",
       "      <td>27439</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>8.368166</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146867</th>\n",
       "      <td>38</td>\n",
       "      <td>686</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>7.083772</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121958</th>\n",
       "      <td>1413</td>\n",
       "      <td>17088</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>159</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>7.729729</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202500 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1   2   3   4    5   6   7    8   9   ...  16        17  18  \\\n",
       "187714   231  27439   5   1   1    9   1   1    1   1  ...   2  6.746477   5   \n",
       "41651     33   6056   2   1   1    3   1   1   17   1  ...   2  5.304034  26   \n",
       "102561   629   3566   2   1   1   36   1   5   31   2  ...   1  6.330550   3   \n",
       "31316     31    536  10   2   2    3   2   1    3   2  ...   4  4.883392  37   \n",
       "113039   106  27439  25   1   1   76   1   6    1   1  ...   2  9.557131   1   \n",
       "...      ...    ...  ..  ..  ..  ...  ..  ..  ...  ..  ...  ..       ...  ..   \n",
       "119879   308  27439   1  17  17  166  16   1   14   2  ...   0  7.304557  23   \n",
       "103694     2    191  11   5   4   31   4   1   48   2  ...   4  5.347076  11   \n",
       "131932   250  27439   5   1   1   85   1   1    1   1  ...   5  8.368166   2   \n",
       "146867    38    686   2   1   1    5   1   1    5   2  ...   1  7.083772  14   \n",
       "121958  1413  17088   9   8   3   97   7   1  159   2  ...   4  7.729729   1   \n",
       "\n",
       "        19  20  21  22  23   24  25  \n",
       "187714   7   8   8   0   3  1.0   0  \n",
       "41651    7   7   7   0   0  1.0  10  \n",
       "102561   6   6   6   0   0  1.0  11  \n",
       "31316    6   6   7   0   1  1.0  17  \n",
       "113039   6   6   6   1   1  1.0  69  \n",
       "...     ..  ..  ..  ..  ..  ...  ..  \n",
       "119879   4   4   4   0   1  0.0   6  \n",
       "103694   6   6   7   0   0  1.0   0  \n",
       "131932  11  11  11   0   0  1.0  16  \n",
       "146867   9   9   9   2   1  3.0  41  \n",
       "121958   9   9  10   0   0  1.0  14  \n",
       "\n",
       "[202500 rows x 26 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-07 14:11:27,771] A new study created in memory with name: no-name-97f23b36-e5c0-4272-a3ff-ace420135cf6\n",
      "[I 2023-08-07 14:11:46,367] Trial 0 finished with value: 0.8678564836735655 and parameters: {'learning_rate': 0.17203021582004538, 'n_estimators': 900, 'max_depth': 22, 'max_bin': 204, 'num_leaves': 279, 'l2_reg': 0.9858348908327655}. Best is trial 0 with value: 0.8678564836735655.\n",
      "[I 2023-08-07 14:11:58,532] Trial 1 finished with value: 0.8588782548181872 and parameters: {'learning_rate': 0.20942974124828925, 'n_estimators': 600, 'max_depth': 13, 'max_bin': 155, 'num_leaves': 323, 'l2_reg': 0.33324771393741603}. Best is trial 0 with value: 0.8678564836735655.\n",
      "[I 2023-08-07 14:12:15,926] Trial 2 finished with value: 0.8785134817944429 and parameters: {'learning_rate': 0.40103786377805345, 'n_estimators': 1050, 'max_depth': 21, 'max_bin': 92, 'num_leaves': 308, 'l2_reg': 0.10088188686900121}. Best is trial 2 with value: 0.8785134817944429.\n",
      "[I 2023-08-07 14:12:38,038] Trial 3 finished with value: 0.8793753817783871 and parameters: {'learning_rate': 0.7055351024587858, 'n_estimators': 1250, 'max_depth': 11, 'max_bin': 248, 'num_leaves': 110, 'l2_reg': 0.7504082280830637}. Best is trial 3 with value: 0.8793753817783871.\n",
      "[I 2023-08-07 14:12:45,072] Trial 4 finished with value: 0.8539914637407788 and parameters: {'learning_rate': 0.34565902774238627, 'n_estimators': 350, 'max_depth': 19, 'max_bin': 69, 'num_leaves': 86, 'l2_reg': 0.2010120554811207}. Best is trial 3 with value: 0.8793753817783871.\n",
      "[I 2023-08-07 14:13:10,819] Trial 5 finished with value: 0.8782069196793272 and parameters: {'learning_rate': 0.23976562067311583, 'n_estimators': 1500, 'max_depth': 24, 'max_bin': 96, 'num_leaves': 463, 'l2_reg': 0.4018738048711082}. Best is trial 3 with value: 0.8793753817783871.\n",
      "[I 2023-08-07 14:13:28,217] Trial 6 finished with value: 0.8712079693467385 and parameters: {'learning_rate': 0.9155584746778108, 'n_estimators': 950, 'max_depth': 11, 'max_bin': 243, 'num_leaves': 147, 'l2_reg': 0.8545911535387526}. Best is trial 3 with value: 0.8793753817783871.\n",
      "[I 2023-08-07 14:13:38,979] Trial 7 finished with value: 0.8693781018005264 and parameters: {'learning_rate': 0.4611469117363638, 'n_estimators': 600, 'max_depth': 22, 'max_bin': 138, 'num_leaves': 303, 'l2_reg': 0.20528677819824784}. Best is trial 3 with value: 0.8793753817783871.\n",
      "[I 2023-08-07 14:13:49,265] Trial 8 finished with value: 0.8680104160936375 and parameters: {'learning_rate': 0.34657854520538445, 'n_estimators': 550, 'max_depth': 18, 'max_bin': 254, 'num_leaves': 143, 'l2_reg': 0.3220130798577154}. Best is trial 3 with value: 0.8793753817783871.\n",
      "[I 2023-08-07 14:14:01,539] Trial 9 finished with value: 0.8632828259904786 and parameters: {'learning_rate': 0.2392647825296523, 'n_estimators': 650, 'max_depth': 15, 'max_bin': 95, 'num_leaves': 121, 'l2_reg': 0.5937368054629301}. Best is trial 3 with value: 0.8793753817783871.\n",
      "[I 2023-08-07 14:14:29,674] Trial 10 finished with value: 0.8595358382419926 and parameters: {'learning_rate': 0.10870626415695019, 'n_estimators': 1500, 'max_depth': 6, 'max_bin': 202, 'num_leaves': 222, 'l2_reg': 1.4457093162548842}. Best is trial 3 with value: 0.8793753817783871.\n",
      "[I 2023-08-07 14:14:52,058] Trial 11 finished with value: 0.88041104303984 and parameters: {'learning_rate': 0.6752050095677231, 'n_estimators': 1200, 'max_depth': 8, 'max_bin': 197, 'num_leaves': 369, 'l2_reg': 0.10166377671543653}. Best is trial 11 with value: 0.88041104303984.\n",
      "[I 2023-08-07 14:15:14,055] Trial 12 finished with value: 0.8762067003773534 and parameters: {'learning_rate': 0.7018941795222261, 'n_estimators': 1250, 'max_depth': 8, 'max_bin': 209, 'num_leaves': 442, 'l2_reg': 0.10057015431382214}. Best is trial 11 with value: 0.88041104303984.\n",
      "[I 2023-08-07 14:15:35,379] Trial 13 finished with value: 0.8809052214589741 and parameters: {'learning_rate': 0.6036554702156075, 'n_estimators': 1250, 'max_depth': 10, 'max_bin': 225, 'num_leaves': 400, 'l2_reg': 0.5429663485274464}. Best is trial 13 with value: 0.8809052214589741.\n",
      "[I 2023-08-07 14:15:56,826] Trial 14 finished with value: 0.8811530488170792 and parameters: {'learning_rate': 0.5774258799960674, 'n_estimators': 1250, 'max_depth': 9, 'max_bin': 179, 'num_leaves': 414, 'l2_reg': 0.5084790994283048}. Best is trial 14 with value: 0.8811530488170792.\n",
      "[I 2023-08-07 14:16:19,373] Trial 15 finished with value: 0.8797357998021849 and parameters: {'learning_rate': 0.5069252170331794, 'n_estimators': 1350, 'max_depth': 10, 'max_bin': 174, 'num_leaves': 401, 'l2_reg': 0.5426952253472918}. Best is trial 14 with value: 0.8811530488170792.\n",
      "[I 2023-08-07 14:16:39,008] Trial 16 finished with value: 0.8684098449749884 and parameters: {'learning_rate': 0.9888530613394829, 'n_estimators': 1050, 'max_depth': 15, 'max_bin': 231, 'num_leaves': 502, 'l2_reg': 0.498675167149855}. Best is trial 14 with value: 0.8811530488170792.\n",
      "[I 2023-08-07 14:16:54,128] Trial 17 finished with value: 0.875388296926138 and parameters: {'learning_rate': 0.5256256671437879, 'n_estimators': 800, 'max_depth': 6, 'max_bin': 170, 'num_leaves': 406, 'l2_reg': 0.6630201416160172}. Best is trial 14 with value: 0.8811530488170792.\n",
      "[I 2023-08-07 14:17:17,296] Trial 18 finished with value: 0.8856303895373883 and parameters: {'learning_rate': 0.5725847818837073, 'n_estimators': 1350, 'max_depth': 13, 'max_bin': 147, 'num_leaves': 508, 'l2_reg': 0.9729227793947609}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:17:41,569] Trial 19 finished with value: 0.8820623402071015 and parameters: {'learning_rate': 0.5006961636591565, 'n_estimators': 1400, 'max_depth': 13, 'max_bin': 127, 'num_leaves': 511, 'l2_reg': 1.232557012655724}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:18:08,374] Trial 20 finished with value: 0.8838655051945872 and parameters: {'learning_rate': 0.3845345139131833, 'n_estimators': 1400, 'max_depth': 13, 'max_bin': 133, 'num_leaves': 491, 'l2_reg': 1.4899254666701154}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:18:33,527] Trial 21 finished with value: 0.8796805778256483 and parameters: {'learning_rate': 0.46999787827488865, 'n_estimators': 1400, 'max_depth': 13, 'max_bin': 123, 'num_leaves': 511, 'l2_reg': 1.4003861674185583}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:18:57,364] Trial 22 finished with value: 0.8809594564873742 and parameters: {'learning_rate': 0.4384138006239894, 'n_estimators': 1400, 'max_depth': 13, 'max_bin': 129, 'num_leaves': 467, 'l2_reg': 1.0659096528051077}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:19:16,434] Trial 23 finished with value: 0.8793224860523357 and parameters: {'learning_rate': 0.3774912107097503, 'n_estimators': 1100, 'max_depth': 16, 'max_bin': 147, 'num_leaves': 484, 'l2_reg': 1.20240135259588}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:19:40,167] Trial 24 finished with value: 0.8830109212383683 and parameters: {'learning_rate': 0.3067996376141168, 'n_estimators': 1400, 'max_depth': 16, 'max_bin': 115, 'num_leaves': 444, 'l2_reg': 1.1648475885152294}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:20:05,032] Trial 25 finished with value: 0.8828550741119047 and parameters: {'learning_rate': 0.3050794985287205, 'n_estimators': 1500, 'max_depth': 17, 'max_bin': 110, 'num_leaves': 443, 'l2_reg': 0.9270002758357051}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:20:25,110] Trial 26 finished with value: 0.8789144502358978 and parameters: {'learning_rate': 0.30918073443282573, 'n_estimators': 1150, 'max_depth': 15, 'max_bin': 112, 'num_leaves': 342, 'l2_reg': 1.4712298962380934}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:20:48,018] Trial 27 finished with value: 0.8751677942504263 and parameters: {'learning_rate': 0.4045477159762807, 'n_estimators': 1350, 'max_depth': 14, 'max_bin': 71, 'num_leaves': 440, 'l2_reg': 1.0637843614937266}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:21:11,680] Trial 28 finished with value: 0.8787923953805903 and parameters: {'learning_rate': 0.28894744720942817, 'n_estimators': 1350, 'max_depth': 19, 'max_bin': 144, 'num_leaves': 356, 'l2_reg': 0.8025745027077265}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:21:28,235] Trial 29 finished with value: 0.8752646947471819 and parameters: {'learning_rate': 0.37640817299475665, 'n_estimators': 950, 'max_depth': 11, 'max_bin': 164, 'num_leaves': 223, 'l2_reg': 0.9766580968358715}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:21:43,552] Trial 30 finished with value: 0.8701932884150103 and parameters: {'learning_rate': 0.25881892757185454, 'n_estimators': 850, 'max_depth': 16, 'max_bin': 111, 'num_leaves': 262, 'l2_reg': 1.2547645587681686}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:22:08,778] Trial 31 finished with value: 0.879829512001256 and parameters: {'learning_rate': 0.3087716521024065, 'n_estimators': 1500, 'max_depth': 17, 'max_bin': 111, 'num_leaves': 444, 'l2_reg': 0.9628781901140682}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:22:33,671] Trial 32 finished with value: 0.8778103616813294 and parameters: {'learning_rate': 0.18960678239973902, 'n_estimators': 1450, 'max_depth': 17, 'max_bin': 151, 'num_leaves': 478, 'l2_reg': 0.8950023692371504}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:22:56,732] Trial 33 finished with value: 0.8772634607382822 and parameters: {'learning_rate': 0.2734125359060465, 'n_estimators': 1300, 'max_depth': 20, 'max_bin': 83, 'num_leaves': 378, 'l2_reg': 1.1573517792034442}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:23:20,920] Trial 34 finished with value: 0.8808389649794715 and parameters: {'learning_rate': 0.3397317122394115, 'n_estimators': 1450, 'max_depth': 12, 'max_bin': 137, 'num_leaves': 423, 'l2_reg': 0.7414589401042689}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:23:42,801] Trial 35 finished with value: 0.8805449509466109 and parameters: {'learning_rate': 0.41950333055030425, 'n_estimators': 1300, 'max_depth': 14, 'max_bin': 119, 'num_leaves': 485, 'l2_reg': 0.9828721248935872}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:23:49,161] Trial 36 finished with value: 0.8533982264672302 and parameters: {'learning_rate': 0.3373517772522092, 'n_estimators': 300, 'max_depth': 16, 'max_bin': 158, 'num_leaves': 449, 'l2_reg': 1.2416420200419371}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:24:09,476] Trial 37 finished with value: 0.8716973475983967 and parameters: {'learning_rate': 0.21733181477846628, 'n_estimators': 1150, 'max_depth': 18, 'max_bin': 91, 'num_leaves': 489, 'l2_reg': 0.8302818112771586}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:24:34,804] Trial 38 finished with value: 0.8786720481252419 and parameters: {'learning_rate': 0.3860274311009713, 'n_estimators': 1450, 'max_depth': 12, 'max_bin': 107, 'num_leaves': 463, 'l2_reg': 1.0793522361531847}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:25:00,838] Trial 39 finished with value: 0.8794786090881556 and parameters: {'learning_rate': 0.28907230083211677, 'n_estimators': 1500, 'max_depth': 20, 'max_bin': 136, 'num_leaves': 326, 'l2_reg': 0.7201255281904936}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:25:09,331] Trial 40 finished with value: 0.8579100177302003 and parameters: {'learning_rate': 0.4424077407699363, 'n_estimators': 450, 'max_depth': 14, 'max_bin': 103, 'num_leaves': 376, 'l2_reg': 0.8796748265295841}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:25:33,404] Trial 41 finished with value: 0.8808517754355529 and parameters: {'learning_rate': 0.5233209883123039, 'n_estimators': 1400, 'max_depth': 13, 'max_bin': 125, 'num_leaves': 510, 'l2_reg': 1.2814548238223284}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:25:56,817] Trial 42 finished with value: 0.875507758744372 and parameters: {'learning_rate': 0.7951194141450809, 'n_estimators': 1300, 'max_depth': 12, 'max_bin': 131, 'num_leaves': 468, 'l2_reg': 1.489260320436059}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:26:20,704] Trial 43 finished with value: 0.8838543608815969 and parameters: {'learning_rate': 0.36921297950167886, 'n_estimators': 1400, 'max_depth': 17, 'max_bin': 119, 'num_leaves': 424, 'l2_reg': 1.133533187651368}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:26:45,190] Trial 44 finished with value: 0.8822218890504108 and parameters: {'learning_rate': 0.34916365995916876, 'n_estimators': 1450, 'max_depth': 17, 'max_bin': 81, 'num_leaves': 420, 'l2_reg': 1.058838902881551}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:27:06,162] Trial 45 finished with value: 0.874661547553293 and parameters: {'learning_rate': 0.25448390605225085, 'n_estimators': 1200, 'max_depth': 18, 'max_bin': 118, 'num_leaves': 428, 'l2_reg': 1.364800590953294}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:27:32,056] Trial 46 finished with value: 0.8852434857127276 and parameters: {'learning_rate': 0.3048909951348469, 'n_estimators': 1500, 'max_depth': 22, 'max_bin': 186, 'num_leaves': 456, 'l2_reg': 0.9092683816458915}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:27:45,784] Trial 47 finished with value: 0.8774358490154921 and parameters: {'learning_rate': 0.41612590626147744, 'n_estimators': 750, 'max_depth': 22, 'max_bin': 180, 'num_leaves': 457, 'l2_reg': 1.1187933341392227}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:28:09,479] Trial 48 finished with value: 0.8828320154614757 and parameters: {'learning_rate': 0.23088045448769756, 'n_estimators': 1350, 'max_depth': 23, 'max_bin': 190, 'num_leaves': 393, 'l2_reg': 1.3115388758240443}. Best is trial 18 with value: 0.8856303895373883.\n",
      "[I 2023-08-07 14:28:30,869] Trial 49 finished with value: 0.8819077046192149 and parameters: {'learning_rate': 0.2663843232050766, 'n_estimators': 1200, 'max_depth': 21, 'max_bin': 213, 'num_leaves': 490, 'l2_reg': 0.8118848057032044}. Best is trial 18 with value: 0.8856303895373883.\n"
     ]
    }
   ],
   "source": [
    "study = opt.create_study(direction='maximize')\n",
    "study.optimize(objective_lgbm, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.5725847818837073,\n",
       " 'n_estimators': 1350,\n",
       " 'max_depth': 13,\n",
       " 'max_bin': 147,\n",
       " 'num_leaves': 508,\n",
       " 'l2_reg': 0.9729227793947609}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79663a0a9d8da7c7d65d8c29430beddf43ec80497536ce6768e4360a34723de0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
